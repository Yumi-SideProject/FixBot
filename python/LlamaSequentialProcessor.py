import json
import requests
import time

# âœ… Llama API ì„¤ì •
API_URL = "https://api.groq.com/openai/v1/chat/completions"
API_KEY = "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"  # ğŸ”¥ API í‚¤ ì„¤ì • í•„ìš”
MODEL = "llama-3.3-70b-versatile"
OUTPUT_FILE = "/content/llm_filtered_sentences.json"

# âœ… JSON íŒŒì¼ ë¡œë“œ
def load_json_files(file_paths):
    sentences = []
    for file_path in file_paths:
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
            sentences.extend([item["sentence"] for item in data])
    return list(sentences)  # ì¤‘ë³µ ì œê±°

# âœ… Llama API ìš”ì²­ í•¨ìˆ˜
def call_llama_api(prompt):
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {API_KEY}"
    }
    payload = {
        "model": MODEL,
        "messages": [{"role": "user", "content": prompt}]
    }

    response = requests.post(API_URL, headers=headers, json=payload)

    if response.status_code == 200:
        result = response.json()
        return result["choices"][0]["message"]["content"]
    else:
        print(f"â— API í˜¸ì¶œ ì˜¤ë¥˜: {response.status_code}")
        return None

# âœ… í”„ë¡¬í”„íŠ¸ ìƒì„±
def generate_prompt(sentences):
    return (
        "ì•„ë˜ ë¬¸ì¥ì´ ì œí’ˆì˜ **ë¬¸ì œ í•´ê²° ë°©ë²•** ë˜ëŠ” **ì„¤ì • ê°€ì´ë“œ**ì¸ì§€ íŒë³„í•´ ì£¼ì„¸ìš”.\n"
        "- í•´ê²° ë°©ë²•ì¼ ê²½ìš°, ê·¸ëŒ€ë¡œ ìœ ì§€\n"
        "- í•´ê²° ë°©ë²•ì´ ì•„ë‹ˆë¼ë©´ ì œì™¸\n"
        "- í•´ê²° ë°©ë²•ì´ ì—¬ëŸ¬ ë¬¸ì¥ìœ¼ë¡œ ì´ë£¨ì–´ì§„ ê²½ìš°, ì—°ê²°ëœ ë¬¸ì¥ë“¤ì„ í•¨ê»˜ ìœ ì§€\n"
        "- ë‹¨ìˆœí•œ ì œí’ˆ ì„¤ëª…ì´ë‚˜ ê¸°ëŠ¥ ì†Œê°œ ë¬¸ì¥ì€ ì œì™¸\n"
        "- ë³„ë„ì˜ ì•ë’¤ ë‚´ìš© ì—†ì´ í•´ë‹¹ ë‚´ìš©ë§Œ ì¶œë ¥.\n"
        "- nutshell, for slack message, in korean\n\n"
        "ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸:\n" + "\n".join(sentences)
    )

# âœ… Llama APIë¥¼ í™œìš©í•œ ë¬¸ì¥ í•„í„°ë§
def filter_sentences(sentences, batch_size=50):
    filtered_sentences = []
    
    for i in range(0, len(sentences), batch_size):
        batch = sentences[i : i + batch_size]
        prompt = generate_prompt(batch)

        response = call_llama_api(prompt)
        if response:
            print(response)  # í•„í„°ë§ëœ ì‘ë‹µ ì¶œë ¥ (ë””ë²„ê¹…)
            filtered_sentences.extend(response.split("\n"))

        # Rate Limit ë°©ì§€ (ëœë¤ ëŒ€ê¸°)
        time.sleep(3 + int(time.time()) % 2)

    return filtered_sentences

# âœ… ê²°ê³¼ ì €ì¥
def save_to_json(sentences, output_file):
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump([{"sentence": s} for s in sentences], f, ensure_ascii=False, indent=4)
    print(f"âœ… í•„í„°ë§ëœ ë¬¸ì¥ ì €ì¥ ì™„ë£Œ: {output_file}")

# âœ… ì‹¤í–‰ ì½”ë“œ
if __name__ == "__main__":
    file_paths = ["/content/Samsung_sentences_1.json", "/content/Samsung_sentences_2.json"]

    sentences = load_json_files(file_paths)
    print(f"ğŸ“Œ ì›ë³¸ ë¬¸ì¥ ê°œìˆ˜: {len(sentences)}")

    filtered_sentences = filter_sentences(sentences)
    print(f"âœ… í•„í„°ë§ í›„ ë¬¸ì¥ ê°œìˆ˜: {len(filtered_sentences)}")

    save_to_json(filtered_sentences, OUTPUT_FILE)
