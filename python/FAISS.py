import json
import faiss
import numpy as np
import torch
from sentence_transformers import SentenceTransformer

# ğŸš€ 1. JSON íŒŒì¼ ë¡œë“œ
file_paths = ["C:/Users/tyumi/Desktop/side_pjt/Samsung_sentences_1.json", "C:/Users/tyumi/Desktop/side_pjt/Samsung_sentences_2.json"]

all_sentences = []
for file_path in file_paths:
    with open(file_path, "r", encoding="utf-8") as f:
        data = json.load(f)
        all_sentences.extend([item["sentence"] for item in data])

print(f"âœ… ë¬¸ì¥ ê°œìˆ˜: {len(all_sentences)}")

# ğŸš€ 2. SBERT ëª¨ë¸ ë¡œë“œ (ê²½ëŸ‰í™” ëª¨ë¸ ì‚¬ìš©)
model_name = "paraphrase-mpnet-base-v2"  # ì •í™•ë„ ìš°ì„  ëª¨ë¸
device = "cuda" if torch.cuda.is_available() else "cpu"  # GPU ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ CUDA ì ìš©
print(f"âœ… ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")

model = SentenceTransformer(model_name, device=device)

# ğŸš€ 3. ë¬¸ì¥ ë²¡í„°í™” (Batch ì²˜ë¦¬)
batch_size = 32  # í•œ ë²ˆì— ì²˜ë¦¬í•  ë¬¸ì¥ ê°œìˆ˜
sentence_embeddings = []

for i in range(0, len(all_sentences), batch_size):
    batch = all_sentences[i:i+batch_size]
    batch_embeddings = model.encode(batch, batch_size=batch_size, convert_to_tensor=True, device=device)
    sentence_embeddings.append(batch_embeddings.cpu().numpy())  # GPU ì‚¬ìš© ì‹œ CPUë¡œ ë³€í™˜

# ëª¨ë“  ë²¡í„° í•©ì¹˜ê¸°
sentence_embeddings = np.vstack(sentence_embeddings)

# ğŸš€ 4. FAISS ì¸ë±ìŠ¤ ìƒì„± (ë‚´ì ê³± ê¸°ë°˜)
vector_dim = sentence_embeddings.shape[1]
faiss_index = faiss.IndexFlatIP(vector_dim)  # ë‚´ì ê³± ê¸°ë°˜
faiss_index.add(np.array(sentence_embeddings, dtype=np.float32))

# ğŸš€ 5. FAISS ì¸ë±ìŠ¤ ì €ì¥
faiss.write_index(faiss_index, "C:/Users/tyumi/Desktop/side_pjt/samsung_faiss.index")
print("âœ… FAISS ì¸ë±ìŠ¤ ì €ì¥ ì™„ë£Œ!")

# ğŸš€ 6. ê²€ìƒ‰ ì˜ˆì œ
query = "ì„¸íƒê¸° ì´ˆê¸°í™” ë°©ë²•"
query_vector = model.encode([query], normalize_embeddings=True, convert_to_tensor=True, device=device)
query_vector = query_vector.cpu().numpy()  # GPU ì‚¬ìš© ì‹œ ë³€í™˜

D, I = faiss_index.search(np.array(query_vector, dtype=np.float32), k=3)  # ìƒìœ„ 3ê°œ ê²€ìƒ‰

print("\nğŸ¯ ê²€ìƒ‰ ê²°ê³¼:")
for idx in I[0]:
    print(f"- {all_sentences[idx]}")
